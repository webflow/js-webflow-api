types:
  RobotsTxtGetResponseRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtGetResponse:
    docs: The robots.txt file for a given site
    properties:
      rules:
        type: optional<list<RobotsTxtGetResponseRulesItem>>
        docs: List of rules for user agents.
      sitemap:
        type: optional<string>
        docs: URL to the sitemap.
    source:
      openapi: v2-data.yml
  RobotsTxtPutRequestRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtPutResponseRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtPutResponse:
    docs: The robots.txt file for a given site
    properties:
      rules:
        type: optional<list<RobotsTxtPutResponseRulesItem>>
        docs: List of rules for user agents.
      sitemap:
        type: optional<string>
        docs: URL to the sitemap.
    source:
      openapi: v2-data.yml
  RobotsTxtDeleteRequestRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtDeleteResponseRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtDeleteResponse:
    docs: The robots.txt file for a given site
    properties:
      rules:
        type: optional<list<RobotsTxtDeleteResponseRulesItem>>
        docs: List of rules for user agents.
      sitemap:
        type: optional<string>
        docs: URL to the sitemap.
    source:
      openapi: v2-data.yml
  RobotsTxtPatchRequestRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtPatchResponseRulesItem:
    properties:
      userAgent:
        type: string
        docs: The user agent the rules apply to.
      allows:
        type: optional<list<string>>
        docs: List of paths allowed for this user agent.
      disallows:
        type: optional<list<string>>
        docs: List of paths disallowed for this user agent.
    source:
      openapi: v2-data.yml
    inline: true
  RobotsTxtPatchResponse:
    docs: The robots.txt file for a given site
    properties:
      rules:
        type: optional<list<RobotsTxtPatchResponseRulesItem>>
        docs: List of rules for user agents.
      sitemap:
        type: optional<string>
        docs: URL to the sitemap.
    source:
      openapi: v2-data.yml
imports:
  root: ../__package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    get:
      path: /sites/{site_id}/robots_txt
      method: GET
      auth:
        - OAuth2:
            - site_config:read
      docs: >
        Retrieve the robots.txt configuration for various user agents.


        <Warning title="Enterprise Only">This endpoint requires an Enterprise
        workspace.</Warning>


        Required scope: `site_config:read`
      source:
        openapi: v2-data.yml
      path-parameters:
        site_id:
          type: string
          docs: Unique identifier for a Site
      display-name: Get robots.txt
      response:
        docs: Request was successful
        type: RobotsTxtGetResponse
        status-code: 200
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.NotFoundError
        - root.TooManyRequestsError
        - root.InternalServerError
      examples:
        - path-parameters:
            site_id: 580e63e98c9a982ac9b8b741
          response:
            body:
              rules:
                - userAgent: googlebot
                  allows:
                    - /public
                  disallows:
                    - /vogon-poetry
                    - /total-perspective-vortex
              sitemap: https://heartofgold.ship/sitemap.xml
    put:
      path: /sites/{site_id}/robots_txt
      method: PUT
      auth:
        - OAuth2:
            - site_config:write
      docs: >
        Replace the `robots.txt` configuration for various user agents.


        <Warning title="Enterprise Only">This endpoint requires an Enterprise
        workspace.</Warning>


        Required scope | `site_config:write`
      source:
        openapi: v2-data.yml
      path-parameters:
        site_id:
          type: string
          docs: Unique identifier for a Site
      display-name: Replace robots.txt
      request:
        name: RobotsTxtPutRequest
        body:
          properties:
            rules:
              type: optional<list<RobotsTxtPutRequestRulesItem>>
              docs: List of rules for user agents.
            sitemap:
              type: optional<string>
              docs: URL to the sitemap.
        content-type: application/json
      response:
        docs: Request was successful
        type: RobotsTxtPutResponse
        status-code: 200
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.NotFoundError
        - root.TooManyRequestsError
        - root.InternalServerError
      examples:
        - path-parameters:
            site_id: 580e63e98c9a982ac9b8b741
          request:
            rules:
              - userAgent: googlebot
                allows:
                  - /public
                disallows:
                  - /vogon-poetry
                  - /total-perspective-vortex
            sitemap: https://heartofgold.ship/sitemap.xml
          response:
            body:
              rules:
                - userAgent: googlebot
                  allows:
                    - /public
                  disallows:
                    - /vogon-poetry
                    - /total-perspective-vortex
              sitemap: https://heartofgold.ship/sitemap.xml
    delete:
      path: /sites/{site_id}/robots_txt
      method: DELETE
      auth:
        - OAuth2:
            - site_config:write
      docs: >
        Remove specific rules for a user-agent in your `robots.txt` file. To
        delete all rules for a user-agent, provide an empty rule set. This will
        remove the user-agent's entry entirely, leaving it subject to your
        site's default crawling behavior.


        **Note:** Deleting a user-agent with no rules will make the user-agent's
        access unrestricted unless other directives apply.


        <Warning title="Enterprise Only">This endpoint requires an Enterprise
        workspace.</Warning>


        Required scope: `site_config:write`
      source:
        openapi: v2-data.yml
      path-parameters:
        site_id:
          type: string
          docs: Unique identifier for a Site
      display-name: Delete robots.txt
      request:
        name: RobotsTxtDeleteRequest
        body:
          properties:
            rules:
              type: optional<list<RobotsTxtDeleteRequestRulesItem>>
              docs: List of rules for user agents.
            sitemap:
              type: optional<string>
              docs: URL to the sitemap.
        content-type: application/json
      response:
        docs: Request was successful
        type: RobotsTxtDeleteResponse
        status-code: 200
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.NotFoundError
        - root.TooManyRequestsError
        - root.InternalServerError
      examples:
        - path-parameters:
            site_id: 580e63e98c9a982ac9b8b741
          request:
            rules:
              - userAgent: '*'
                allows:
                  - /public
                disallows:
                  - /bubbles
          response:
            body:
              rules:
                - userAgent: googlebot
                  allows:
                    - /public
                  disallows:
                    - /vogon-poetry
                    - /total-perspective-vortex
              sitemap: https://heartofgold.ship/sitemap.xml
    patch:
      path: /sites/{site_id}/robots_txt
      method: PATCH
      auth:
        - OAuth2:
            - site_config:write
      docs: >
        Update the `robots.txt` configuration for various user agents.


        <Warning title="Enterprise Only">This endpoint requires an Enterprise
        workspace.</Warning>


        Required scope | `site_config:write`
      source:
        openapi: v2-data.yml
      path-parameters:
        site_id:
          type: string
          docs: Unique identifier for a Site
      display-name: Update robots.txt
      request:
        name: RobotsTxtPatchRequest
        body:
          properties:
            rules:
              type: optional<list<RobotsTxtPatchRequestRulesItem>>
              docs: List of rules for user agents.
            sitemap:
              type: optional<string>
              docs: URL to the sitemap.
        content-type: application/json
      response:
        docs: Request was successful
        type: RobotsTxtPatchResponse
        status-code: 200
      errors:
        - root.BadRequestError
        - root.UnauthorizedError
        - root.NotFoundError
        - root.TooManyRequestsError
        - root.InternalServerError
      examples:
        - path-parameters:
            site_id: 580e63e98c9a982ac9b8b741
          request:
            rules:
              - userAgent: googlebot
                allows:
                  - /public
                disallows:
                  - /vogon-poetry
                  - /total-perspective-vortex
            sitemap: https://heartofgold.ship/sitemap.xml
          response:
            body:
              rules:
                - userAgent: googlebot
                  allows:
                    - /public
                  disallows:
                    - /vogon-poetry
                    - /total-perspective-vortex
              sitemap: https://heartofgold.ship/sitemap.xml
  source:
    openapi: v2-data.yml
